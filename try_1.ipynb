{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddd17ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbbf2ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "base_path = base_path = Path.cwd().parent / \"data\" / \"exp1\" / \"session_20250705_2207\"\n",
    "df_eeg= pd.read_csv(base_path / 'eeg_data.csv')\n",
    "df_gui = pd.read_csv(base_path / 'gui_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dff9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time thingy if thats all needed\n",
    "df_gui['timestamp'] = df_gui['timestamp'] - df_gui['timestamp'].iloc[0]\n",
    "df_eeg['timestamp'] = df_eeg['timestamp'] - df_gui['timestamp'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5855bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEG: strech time vector to resolve duplicate timestamps\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d8fdd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated sampling frequency: 32.00 Hz\n"
     ]
    }
   ],
   "source": [
    "# Estimate sampling frequency (in Hz)\n",
    "timestamps = df_eeg['timestamp'].values\n",
    "dt = np.median(np.diff(timestamps))  # assume constant sampling\n",
    "fs = 1.0 / dt\n",
    "print(f\"Estimated sampling frequency: {fs:.2f} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605be485",
   "metadata": {},
   "source": [
    "## Things to See\n",
    "- **A** – Average time for the Epochs  \n",
    "- **B** – The electrode graph \n",
    "\n",
    "## Preprocessing List\n",
    "- **A** – Bandpass filter 1–20 Hz \n",
    "\n",
    "\n",
    "## The List to Try\n",
    "\n",
    "### A. Normalization\n",
    "- **A1** – Demean per epoch, then average  \n",
    "- **A2** – Average, then demean  \n",
    "- **A3** – Just average  \n",
    "\n",
    "### B. Data Usage\n",
    "- **B1** – Time values between 290 ms to end  \n",
    "- **B2** – Time values between 290 ms to end, then decimate by 4  \n",
    "- **B3** – P300 amplitude: peak in 290–500 ms ±10 ms window  \n",
    "- **B4** – P300 amplitude: max in 290–500 ms  \n",
    "- **B5** – P300 amplitude at exactly 300 ms  \n",
    "\n",
    "### C. Feature Selection\n",
    "- **C1** – Fisher LDA  \n",
    "- **C2** - Statistically significant electrodes\n",
    "- **C3** - Manual Feature selection as \"M = mean 8 electrode P300 values\" and P300/M for normalization\n",
    "\n",
    "### M. ML Methods\n",
    " ? Should I have output as binary and prob of correct or selection from 1-2-3 ? \n",
    "- **M1** – LDA  \n",
    "- **M2** – SVM  \n",
    "- **M3** – DAWN + LDA  \n",
    "- **M4** - Random Forest with redacted columns\n",
    "\n",
    "\n",
    "\n",
    "#### Later\n",
    "- Try and discard the epochs with eye blinking with abs (max -min) and threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f8f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_average_epochs_by_stimulus(df_eeg, df_gui, fs=128, post_time=0.6, n_average=0, normalization=\"A1\",blink_channel_idx=0, blink_threshold=120):\n",
    "    \"\"\"\n",
    "    Extracts EEG epochs aligned to GUI stimulus timestamps,\n",
    "    applies selected normalization (A1, A2, A3),\n",
    "    and returns the averaged epoch per stimulus.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_eeg : pd.DataFrame\n",
    "        EEG data with 'timestamp' column and one column per channel.\n",
    "    df_gui : pd.DataFrame\n",
    "        GUI data with 'timestamp' and 'stimulus' columns.\n",
    "    fs : int or float\n",
    "        Sampling frequency in Hz.\n",
    "    post_time : float\n",
    "        Time after stimulus in seconds.\n",
    "    n_average : int\n",
    "        Number of epochs to average per stimulus. 0 means use all.\n",
    "    normalization : str\n",
    "        'A1' = Demean each epoch, then average  \n",
    "        'A2' = Average all epochs, then demean  \n",
    "        'A3' = Just average without any demeaning\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    averaged_epochs : dict\n",
    "        Dictionary with keys {1, 2, 3}, each containing array of shape (epoch_len, n_channels)\n",
    "    \"\"\"\n",
    "    eeg_X = df_eeg.drop(columns='timestamp').values\n",
    "    n_samples, n_channels = eeg_X.shape\n",
    "\n",
    "    epoch_len = int(post_time * fs)\n",
    "    epoch_offsets = np.arange(epoch_len)[None, :]\n",
    "\n",
    "    averaged_epochs = {}\n",
    "\n",
    "    for stim in [1, 2, 3]:\n",
    "        gui_t = df_gui[df_gui['stimulus'] == stim]['timestamp'].values \n",
    "        gui_eeg_idx = np.searchsorted(eeg_t, gui_t)\n",
    "        valid_mask = (gui_eeg_idx + epoch_len < n_samples)\n",
    "        gui_eeg_idx = gui_eeg_idx[valid_mask]\n",
    "\n",
    "        if len(gui_eeg_idx) == 0:\n",
    "            averaged_epochs[stim] = np.full((epoch_len, n_channels), np.nan)\n",
    "            continue\n",
    "\n",
    "        if n_average > 0:\n",
    "            gui_eeg_idx = gui_eeg_idx[:n_average]\n",
    "\n",
    "        epochs = eeg_X[gui_eeg_idx[:, None] + epoch_offsets]  # (n_epochs, epoch_len, n_channels)\n",
    "\n",
    "        # Fast vectorized blink rejection (based on peak-to-peak amplitude)\n",
    "        blink_channel = epochs[:, :, blink_channel_idx]\n",
    "        ptp_amplitude = np.ptp(blink_channel, axis=1)\n",
    "        keep_mask = ptp_amplitude <= blink_threshold\n",
    "        epochs = epochs[keep_mask]\n",
    "\n",
    "        if normalization == \"A1\":\n",
    "            epoch_mean = epochs.mean(axis=1, keepdims=True)\n",
    "            epochs_demeaned = epochs - epoch_mean\n",
    "            averaged = epochs_demeaned.mean(axis=0)\n",
    "\n",
    "        elif normalization == \"A2\":\n",
    "            averaged = epochs.mean(axis=0)\n",
    "            averaged = averaged - averaged.mean(axis=0, keepdims=True)\n",
    "\n",
    "        elif normalization == \"A3\":\n",
    "            averaged = epochs.mean(axis=0)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid normalization type. Use 'A1', 'A2', or 'A3'.\")\n",
    "\n",
    "        averaged_epochs[stim] = averaged\n",
    "\n",
    "    return averaged_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ce485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_averaged_epochs(averaged_epochs, fs=250, feature_type=\"B1\"):\n",
    "    \"\"\"\n",
    "    Extracts features from averaged EEG epochs using different strategies (B1-B5).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    averaged_epochs : dict\n",
    "        Dictionary with keys {1, 2, 3}, each containing a NumPy array of shape (epoch_len, n_channels),\n",
    "        representing the averaged EEG response for that stimulus.\n",
    "    fs : int\n",
    "        Sampling frequency in Hz.\n",
    "    feature_type : str\n",
    "        One of the following options:\n",
    "\n",
    "        - \"B1\" - Time-series from 290 ms to end of epoch (shape: T × C)\n",
    "        - \"B2\" - Same as B1, but decimated by 4 (shape: T/4 × C)\n",
    "        - \"B3\" - P300 amplitude: mean ±10 ms around peak in 290-500 ms window (shape: C,)\n",
    "        - \"B4\" - P300 amplitude: max value in 290-500 ms (shape: C,)\n",
    "        - \"B5\" - P300 amplitude at exactly 310 ms (shape: C,)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features : dict\n",
    "        Dictionary with keys {1, 2, 3}, each containing:\n",
    "        - For B1 and B2: a time - channel matrix (2D array)\n",
    "        - For B3-B5: a channel-wise summary vector (1D array)\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    start_ms = 290\n",
    "    p300_window = (290, 500)\n",
    "    window_size_ms = 10\n",
    "    t_300_ms = 310\n",
    "\n",
    "    for stim, epoch in averaged_epochs.items():\n",
    "        if epoch is None or np.all(np.isnan(epoch)):\n",
    "            features[stim] = None\n",
    "            continue\n",
    "\n",
    "        n_time, n_channels = epoch.shape\n",
    "        time_vector = np.arange(n_time) * (1000 / fs)  # time in ms\n",
    "\n",
    "        if feature_type == \"B1\":\n",
    "            # Time-series from 290 ms onward (shape: T × C)\n",
    "            mask = time_vector >= start_ms\n",
    "            feat = epoch[mask]  # shape: (T_b1, C)\n",
    "\n",
    "        elif feature_type == \"B2\":\n",
    "            # Time-series from 290 ms onward, decimated by 4 (shape: T/4 × C)\n",
    "            mask = time_vector >= start_ms\n",
    "            feat = epoch[mask][::4]  # shape: (T_b2, C)\n",
    "\n",
    "        elif feature_type == \"B3\":\n",
    "            # Peak in 290–500 → average ±10 ms window around it\n",
    "            mask = (time_vector >= p300_window[0]) & (time_vector <= p300_window[1])\n",
    "            windowed = epoch[mask]\n",
    "            time_in_window = time_vector[mask]\n",
    "            peak_idx = np.argmax(windowed, axis=0)\n",
    "            feat = []\n",
    "            for ch in range(n_channels):\n",
    "                center_time = time_in_window[peak_idx[ch]]\n",
    "                win_mask = (time_vector >= center_time - window_size_ms) & (time_vector <= center_time + window_size_ms)\n",
    "                feat.append(epoch[win_mask, ch].mean())\n",
    "            feat = np.array(feat)  # shape: (C,)\n",
    "\n",
    "        elif feature_type == \"B4\":\n",
    "            # Max amplitude between 290–500 ms (shape: C,)\n",
    "            mask = (time_vector >= p300_window[0]) & (time_vector <= p300_window[1])\n",
    "            feat = epoch[mask].max(axis=0)\n",
    "\n",
    "        elif feature_type == \"B5\":\n",
    "            # Amplitude at exactly 300 ms (shape: C,)\n",
    "            idx_300 = np.argmin(np.abs(time_vector - t_300_ms))\n",
    "            feat = epoch[idx_300]\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid feature_type. Use 'B1', 'B2', 'B3', 'B4', or 'B5'.\")\n",
    "\n",
    "        features[stim] = feat\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f481d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_trials(df_eeg, df_gui, fs=128, post_time=0.6, n_average=0, normalization=\"A1\",feature_type=\"B3\", blink_channel_idx=0, blink_threshold=120):\n",
    "    \"\"\"\n",
    "    Iteratively processes all trials in df_gui using extract_and_average_epochs_by_stimulus.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_eeg : pd.DataFrame\n",
    "        EEG data.\n",
    "    df_gui : pd.DataFrame\n",
    "        GUI data with 'trial', 'timestamp', and 'stimulus'.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    all_averaged_epochs : list of dicts\n",
    "        List of averaged epoch dicts from each trial.\n",
    "    \"\"\"\n",
    "    all_averaged_epochs = []\n",
    "    \n",
    "    # Group df_gui by each trial\n",
    "    for trial_id, trial_gui in df_gui.groupby('trial'):\n",
    "\n",
    "        averaged_epochs = extract_and_average_epochs_by_stimulus(df_eeg=df_eeg,df_gui=trial_gui,fs=fs,post_time=post_time,n_average=n_average,\n",
    "            normalization=normalization,blink_channel_idx=blink_channel_idx,blink_threshold=blink_threshold)\n",
    "        \n",
    "        target = trial_gui['target'].iloc[0] # target for the trial\n",
    "        features_avg_epoch = extract_features_from_averaged_epochs(averaged_epochs, fs=fs, feature_type=feature_type)\n",
    "\n",
    "        all_averaged_epochs.append(averaged_epochs)\n",
    "    \n",
    "    return all_averaged_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd5be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_binary_classification_from_trial(features_dict, target_class):\n",
    "    \"\"\"\n",
    "    Converts multi-class trial into binary classification sample set\n",
    "    Parameters\n",
    "    ----------\n",
    "    features_dict : dict\n",
    "        Dictionary {class_index: feature_vector (shape C,)} for current trial.\n",
    "    target_class : int\n",
    "        Index of the true target class (e.g., 0, 1, or 2)\n",
    "    Returns\n",
    "    -------\n",
    "    X : np.ndarray, shape (3, C)\n",
    "        Feature matrix for all 3 stimuli.\n",
    "    y : np.ndarray, shape (3,)\n",
    "        Binary labels: 1 if class is the target, 0 otherwise.\n",
    "    \"\"\"\n",
    "    keys = sorted(features_dict.keys())  # ensure consistent order\n",
    "    X = np.vstack([features_dict[k] for k in keys])\n",
    "    y = np.array([1 if k == target_class else 0 for k in keys])\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237a1eb5",
   "metadata": {},
   "source": [
    "I need feature selection\n",
    "    - RF \n",
    "\n",
    "I can also try Common Spatial Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2128e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "# X: shape (n_samples, n_features)\n",
    "# y: shape (n_samples,), values as 1, 0\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif, k=10)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "selected_indices = selector.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0cacb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction      \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# X: shape (n_samples, n_features)\n",
    "# y: shape (n_samples,), values as 1, 0\n",
    "\n",
    "# Fischer LDA\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "X_lda = lda.fit_transform(X, y)   # Reduced features\n",
    "y_pred = lda.predict(X)           # Class predictions (if needed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd9495",
   "metadata": {},
   "source": [
    "I am doing the feature X and y preparer for B3-B5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50615bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 11.97 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "epochs = extract_epochs_by_stimulus(df_eeg, df_gui, fs=250, post_time=0.8)\n",
    "\n",
    "eeg_epochs_1 = epochs[1]\n",
    "eeg_epochs_2 = epochs[2]\n",
    "eeg_epochs_3 = epochs[3]\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Execution time: {(end - start)*1000:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504e3368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demean the epochs globally\n",
    "eeg_epochs_1_demeaned = global_demean_epochs(eeg_epochs_1)\n",
    "eeg_epochs_2_demeaned = global_demean_epochs(eeg_epochs_2)\n",
    "eeg_epochs_3_demeaned = global_demean_epochs(eeg_epochs_3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
