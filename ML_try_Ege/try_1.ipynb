{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd17ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6660bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport help_func\n",
    "\n",
    "from help_func import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbbf2ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "base_path = base_path = Path.cwd().parent  / \"data\"/ \"exp2_box_ISI300\" /\"session_20250710_1721_Ege\"\n",
    "df_eeg= pd.read_csv(base_path / 'eeg_data.csv')\n",
    "df_gui = pd.read_csv(base_path / 'gui_data.csv')\n",
    "\n",
    "# Time start point = 0\n",
    "df_gui['timestamp'] = df_gui['timestamp'] - df_eeg['timestamp_ux'].iloc[0]\n",
    "df_eeg['timestamp_ux'] = df_eeg['timestamp_ux'] - df_eeg['timestamp_ux'].iloc[0]\n",
    "\n",
    "# Interpolate plateaus in ux timestamp\n",
    "df_eeg = interpolate_plateaus_in_ux(df_eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d8fdd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated sampling frequency: 127.89 Hz\n"
     ]
    }
   ],
   "source": [
    "# Estimate sampling frequency (in Hz)\n",
    "timestamps = df_eeg['timestamp_ux'].values\n",
    "dt = np.median(np.diff(timestamps))  # assume constant sampling\n",
    "fs = 1.0 / dt\n",
    "print(f\"Estimated sampling frequency: {fs:.2f} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605be485",
   "metadata": {},
   "source": [
    "## Things to See\n",
    "- **A** – Average time for the Epochs  \n",
    "- **B** – The electrode graph \n",
    "\n",
    "## Preprocessing List\n",
    "- **A** – Bandpass filter 1–20 Hz \n",
    "\n",
    "\n",
    "## The List to Try\n",
    "\n",
    "### A. Normalization\n",
    "- **A1** – Demean per epoch, then average  \n",
    "- **A2** – Average, then demean  \n",
    "- **A3** – Just average  \n",
    "\n",
    "### B. Data Usage\n",
    "- **B1** – Time values between 290 ms to end  \n",
    "- **B2** – Time values between 290 ms to end, then decimate by 4  \n",
    "- **B3** – P300 amplitude: peak in 290–500 ms ±10 ms window  \n",
    "- **B4** – P300 amplitude: max in 290–500 ms  \n",
    "- **B5** – P300 amplitude at exactly 300 ms  \n",
    "\n",
    "### C. Feature Selection\n",
    "- **C1** – Fisher LDA  \n",
    "- **C2** - Statistically significant electrodes\n",
    "\n",
    "### M. ML Methods\n",
    " ? Should I have output as binary and prob of correct or selection from 1-2-3 ? \n",
    "- **M1** – LDA  \n",
    "- **M2** – SVM  \n",
    "- **M3** – DAWN + LDA  \n",
    "- **M4** - Random Forest with redacted columns\n",
    "\n",
    "\n",
    "\n",
    "#### Later\n",
    "- Try and discard the epochs with eye blinking with abs (max -min) and threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70fc1fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_gui.iloc[0:36].copy()\n",
    "avg = extract_and_average_epochs_by_stimulus(df_eeg, df, fs=128, post_time=0.6, n_average=0, normalization=\"A1\",blink_channel_idx=0, blink_threshold=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f481d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_trials(df_eeg, df_gui, fs=128, post_time=0.6, n_average=0, normalization=\"A1\",feature_type=\"B3\", blink_channel_idx=0, blink_threshold=120):\n",
    "    \"\"\"\n",
    "    Iteratively processes all trials in df_gui using extract_and_average_epochs_by_stimulus.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_eeg : pd.DataFrame\n",
    "        EEG data.\n",
    "    df_gui : pd.DataFrame\n",
    "        GUI data with 'trial', 'timestamp', and 'stimulus'.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    all_averaged_epochs : list of dicts\n",
    "        List of averaged epoch dicts from each trial.\n",
    "    \"\"\"\n",
    "    all_averaged_epochs = []\n",
    "    \n",
    "    # Group df_gui by each trial\n",
    "    for trial_id, trial_gui in df_gui.groupby('trial'):\n",
    "\n",
    "        averaged_epochs = extract_and_average_epochs_by_stimulus(df_eeg=df_eeg,df_gui=trial_gui,fs=fs,post_time=post_time,n_average=n_average,\n",
    "            normalization=normalization,blink_channel_idx=blink_channel_idx,blink_threshold=blink_threshold)\n",
    "        \n",
    "        target = trial_gui['target'].iloc[0] # target for the trial\n",
    "        features_avg_epoch = extract_features_from_averaged_epochs(averaged_epochs, fs=fs, feature_type=feature_type)\n",
    "        all_averaged_epochs.append(averaged_epochs)\n",
    "    \n",
    "    return all_averaged_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b1730b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eeg_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m all_averaged_epochs = \u001b[43mprocess_all_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_eeg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_gui\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_time\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_average\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mA1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mB3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblink_channel_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblink_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m120\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mprocess_all_trials\u001b[39m\u001b[34m(df_eeg, df_gui, fs, post_time, n_average, normalization, feature_type, blink_channel_idx, blink_threshold)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Group df_gui by each trial\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m trial_id, trial_gui \u001b[38;5;129;01min\u001b[39;00m df_gui.groupby(\u001b[33m'\u001b[39m\u001b[33mtrial\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     averaged_epochs = \u001b[43mextract_and_average_epochs_by_stimulus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_eeg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_eeg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf_gui\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial_gui\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpost_time\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpost_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_average\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_average\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnormalization\u001b[49m\u001b[43m,\u001b[49m\u001b[43mblink_channel_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblink_channel_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mblink_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblink_threshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     target = trial_gui[\u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m].iloc[\u001b[32m0\u001b[39m] \u001b[38;5;66;03m# target for the trial\u001b[39;00m\n\u001b[32m     26\u001b[39m     features_avg_epoch = extract_features_from_averaged_epochs(averaged_epochs, fs=fs, feature_type=feature_type)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mextract_and_average_epochs_by_stimulus\u001b[39m\u001b[34m(df_eeg, df_gui, fs, post_time, n_average, normalization, blink_channel_idx, blink_threshold)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m stim \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m]:\n\u001b[32m     38\u001b[39m     gui_t = df_gui[df_gui[\u001b[33m'\u001b[39m\u001b[33mstimulus\u001b[39m\u001b[33m'\u001b[39m] == stim][\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m].values \n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     gui_eeg_idx = np.searchsorted(\u001b[43meeg_t\u001b[49m, gui_t)\n\u001b[32m     40\u001b[39m     valid_mask = (gui_eeg_idx + epoch_len < n_samples)\n\u001b[32m     41\u001b[39m     gui_eeg_idx = gui_eeg_idx[valid_mask]\n",
      "\u001b[31mNameError\u001b[39m: name 'eeg_t' is not defined"
     ]
    }
   ],
   "source": [
    "all_averaged_epochs = process_all_trials(df_eeg, df_gui, fs=fs, post_time=0.6, n_average=0, normalization=\"A1\", feature_type=\"B3\", blink_channel_idx=0, blink_threshold=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd5be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_binary_classification_from_trial(features_dict, target_class):\n",
    "    \"\"\"\n",
    "    Converts multi-class trial into binary classification sample set\n",
    "    Parameters\n",
    "    ----------\n",
    "    features_dict : dict\n",
    "        Dictionary {class_index: feature_vector (shape C,)} for current trial.\n",
    "    target_class : int\n",
    "        Index of the true target class (e.g., 0, 1, or 2)\n",
    "    Returns\n",
    "    -------\n",
    "    X : np.ndarray, shape (3, C)\n",
    "        Feature matrix for all 3 stimuli.\n",
    "    y : np.ndarray, shape (3,)\n",
    "        Binary labels: 1 if class is the target, 0 otherwise.\n",
    "    \"\"\"\n",
    "    keys = sorted(features_dict.keys())  # ensure consistent order\n",
    "    X = np.vstack([features_dict[k] for k in keys])\n",
    "    y = np.array([1 if k == target_class else 0 for k in keys])\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237a1eb5",
   "metadata": {},
   "source": [
    "I need feature selection\n",
    "    - RF \n",
    "\n",
    "I can also try Common Spatial Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2128e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "# X: shape (n_samples, n_features)\n",
    "# y: shape (n_samples,), values as 1, 0\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif, k=10)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "selected_indices = selector.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0cacb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction      \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# X: shape (n_samples, n_features)\n",
    "# y: shape (n_samples,), values as 1, 0\n",
    "\n",
    "# Fischer LDA\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "X_lda = lda.fit_transform(X, y)   # Reduced features\n",
    "y_pred = lda.predict(X)           # Class predictions (if needed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd9495",
   "metadata": {},
   "source": [
    "I am doing the feature X and y preparer for B3-B5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50615bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 11.97 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "epochs = extract_epochs_by_stimulus(df_eeg, df_gui, fs=250, post_time=0.8)\n",
    "\n",
    "eeg_epochs_1 = epochs[1]\n",
    "eeg_epochs_2 = epochs[2]\n",
    "eeg_epochs_3 = epochs[3]\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Execution time: {(end - start)*1000:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504e3368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demean the epochs globally\n",
    "eeg_epochs_1_demeaned = global_demean_epochs(eeg_epochs_1)\n",
    "eeg_epochs_2_demeaned = global_demean_epochs(eeg_epochs_2)\n",
    "eeg_epochs_3_demeaned = global_demean_epochs(eeg_epochs_3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
